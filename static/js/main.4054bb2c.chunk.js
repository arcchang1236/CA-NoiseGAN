(this.webpackJsonpprojectize=this.webpackJsonpprojectize||[]).push([[0],{191:function(e,a,n){e.exports=n(341)},341:function(e,a,n){"use strict";n.r(a);var t=n(0),r=n.n(t),i=n(10),o=n.n(i),l=n(18),c=n(90),m=n(11),s=n(181),u=n(393),d=n(394),g=n(386),h=n(345),p=n(380),f=n(397),b=n(382),E=n(383),_=n(390),v=n(387),C=n(388),N=n(389),A=n(376),w=n(169),x=n.n(w),y=n(378),k=n(170),R=n.n(k),S=n(171),M=n.n(S),j=Object(A.a)((function(e){var a;return{toolbar:{borderBottom:"1px solid ".concat(e.palette.divider),backgroundColor:"#003153",color:"#fff",zIndex:0},toolbarTitle:{flex:1},toolbarSecondary:(a={justifyContent:"center",backgroundColor:"#b0d1f3",zIndex:0,"& > a":{padding:e.spacing(0,5)}},Object(l.a)(a,e.breakpoints.down("md"),{"& > a":{padding:e.spacing(0,3)}}),Object(l.a)(a,e.breakpoints.down("xs"),{"& > a":{padding:e.spacing(0,1)}}),a),toolbarLink:{padding:e.spacing(1),flexShrink:0}}}));function L(e){var a=j(),n=e.sections,t=e.title,i=e.githubPage;return r.a.createElement(r.a.Fragment,null,r.a.createElement(y.a,{className:a.toolbar},r.a.createElement(h.a,{component:"h2",variant:"h5",color:"inherit",align:"center",noWrap:!0,className:a.toolbarTitle},t)),r.a.createElement(y.a,{component:"nav",variant:"dense",className:a.toolbarSecondary},n.map((function(e){return r.a.createElement(p.a,{color:"inherit",noWrap:!0,key:e.title,variant:"body2",href:"/CA-NoiseGAN"+e.url,className:a.toolbarLink},e.title)}))),i?r.a.createElement(M.a,null,r.a.createElement(R.a,{href:i})):"")}var P=n(396),B=n(381),F=Object(A.a)((function(e){return{title:{padding:e.spacing(3,0),margin:e.spacing(6,0,0,0)},text:{fontFamily:"Source Serif Pro"}}}));function V(e){var a=F(),n=e.name,t=e.anchor,i=e.fontVariant;return r.a.createElement(P.a,{className:a.title,id:t},r.a.createElement(h.a,{className:a.text,align:"left",component:"h4",variant:i?i.variant:"h4",gutterBottom:!0},n),r.a.createElement(B.a,null))}var W=Object(A.a)((function(e){return{authorRoot:{flexGrow:1},affiliationRoot:{flexGrow:1,padding:e.spacing(0,0,6)}}}));function O(e){var a=W(),n=e.authors,t=e.affiliations;return r.a.createElement(r.a.Fragment,null,r.a.createElement(b.a,{container:!0,justify:"center",className:a.authorRoot,spacing:2},n.map((function(e){return r.a.createElement(b.a,{item:!0,key:e.name},r.a.createElement(h.a,{component:"h3",variant:"h6"},r.a.createElement(p.a,{href:e.url},e.name),r.a.createElement("sup",null,e.affiliation)))}))),r.a.createElement(b.a,{container:!0,justify:"center",className:a.affiliationRoot,spacing:2},t.map((function(e){return r.a.createElement(b.a,{item:!0,key:e.name},r.a.createElement(h.a,{component:"h4",variant:"h6"},e.name,r.a.createElement("sup",null,e.number)))}))))}var H=n(384),D=Object(A.a)((function(e){return{bannerImg:{padding:e.spacing(2,0,6),backgroundColor:"transparent"}}}));function T(e){var a=D(),n=e.title,t=e.imageSrc,i=e.elevation;return r.a.createElement(E.a,{elevation:i,className:a.bannerImg},r.a.createElement(b.a,{alignItems:"center",justify:"center",container:!0},r.a.createElement(h.a,{component:"h3",variant:"subtitle1",color:"inherit",gutterBottom:!0},n),r.a.createElement(H.a,{component:"img",alt:n,src:t,title:n})))}var I=n(385),G=Object(A.a)({root:{background:"linear-gradient(87deg, #FE6B8B 30%, #FF8E63 90%)",border:0,borderRadius:3,boxShadow:"0 3px 5px 2px rgba(255, 105, 135, .3)",color:"white",height:48,padding:"0 30px"}});function z(e){var a=G(),n=e.text,t=e.link;return r.a.createElement(I.a,{className:a.root,href:t},n)}var K=Object(A.a)((function(e){return{footer:{padding:e.spacing(6,0)}}}));function Z(e){var a=K(),n=e.authorName,t=e.githubPage;return r.a.createElement("footer",{className:a.footer},r.a.createElement(g.a,{maxWidth:"lg"},r.a.createElement(h.a,{variant:"body2",color:"textSecondary",align:"center"},"Copyright \xa9 ",r.a.createElement(p.a,{color:"inherit",href:t},n)," , Template \xa9 ",r.a.createElement(p.a,{color:"inherit",href:"https://github.com/leVirve"},"Hung-Jin Lin")," ",(new Date).getFullYear(),".")))}var q=Object(A.a)((function(e){return{main:{textAlign:"center"},titleHead:{paddingTop:e.spacing(8),paddingBottom:e.spacing(4),fontFamily:"Source Serif Pro","& > a > *":{margin:e.spacing(.5)}},bibtexSpan:{backgroundColor:e.palette.grey[200],marginTop:e.spacing(2),padding:e.spacing(1,4)},iconText:{wordWrap:"break-word"}}}));function J(){var e=q();return r.a.createElement("div",{className:e.main},r.a.createElement(L,{title:"Learning Camera-Aware Noise Models",githubPage:"https://github.com/arcchang1236/CA-NoiseGAN",sections:[{title:"Home",url:"#"},{title:"Abstract",url:"#abstract"},{title:"Paper",url:"#paper"},{title:"Video",url:"#video"},{title:"Downloadables",url:"#download"},{title:"Demo",url:"#results"},{title:"Resources",url:"#acknowledgments"},{title:"References",url:"#reference"}]}),r.a.createElement(g.a,{maxWidth:"lg"},r.a.createElement(U,null),r.a.createElement(Q,null),r.a.createElement(X,null),r.a.createElement($,null),r.a.createElement(ee,null),r.a.createElement(ae,null),r.a.createElement(ne,null)),r.a.createElement(Z,{authorName:"Ke-Chi Chang",githubPage:"https://github.com/arcchang1236"}))}function U(){var e=q(),a="".concat("/CA-NoiseGAN","/images/teaser.png");return r.a.createElement(r.a.Fragment,null,r.a.createElement(h.a,{component:"h1",variant:"h3",gutterBottom:!0,className:e.titleHead},"Learning Camera-Aware Noise Models ",r.a.createElement("br",null),[{text:"ECCV 2020",url:"https://eccv2020.eu/"}].map((function(e){return r.a.createElement(p.a,{key:e.text,href:e.url,target:"_blank",rel:"noopener"},r.a.createElement(f.a,{label:e.text}))}))),r.a.createElement(Y,null),r.a.createElement(T,{elevation:0,imageSrc:a}),r.a.createElement(z,{text:"Download Code / Results",link:"#download"}))}function Y(){return r.a.createElement(r.a.Fragment,null,r.a.createElement(O,{authors:[{name:"Ke-Chi Chang",url:"http://arcchang1236.github.io/",affiliation:"1,2"},{name:"Ren Wang",url:"https://tw.linkedin.com/in/ren-wang-61b273160",affiliation:"1"},{name:"Hung-Jin Lin",url:"https://github.com/leVirve",affiliation:"1"},{name:"Yu-Lun Liu",url:"https://www.cmlab.csie.ntu.edu.tw/~yulunliu",affiliation:"1"},{name:"Chia-Ping Chen",url:"https://tw.linkedin.com/in/chia-ping-chen-81674078",affiliation:"1"},{name:"Yu-Lin Chang",url:"https://scholar.google.com/citations?user=0O9rukQAAAAJ&hl=en",affiliation:"1"},{name:"Hwann-Tzong Chen",url:"https://htchen.github.io/",affiliation:"2"}],affiliations:[{number:"1",name:"MediaTek Inc.",url:"https://www.mediatek.tw/"},{number:"2",name:"National Tsing Hua University",url:""}]}))}function Q(){var e="".concat("/CA-NoiseGAN","/images/network.png");return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"abstract",name:"Abstract"}),r.a.createElement(h.a,{component:"h3",variant:"h6",align:"left",paragraph:!0},"Modeling imaging sensor noise is a fundamental problem for image processing and computer vision applications. While most previous works adopt statistical noise models, real-world noise is far more complicated and beyond what these models can describe. To tackle this issue, we propose a data-driven approach, where a generative noise model is learned from real-world noise. The proposed noise model is camera-aware, that is, different noise characteristics of different camera sensors can be learned simultaneously, and a single learned noise model can generate different noise for different camera sensors. Experimental results show that our method quantitatively and qualitatively outperforms existing statistical noise models and learning-based methods."),r.a.createElement("div",{style:{maxWidth:800,height:"auto",margin:"auto"}},r.a.createElement(T,{elevation:0,imageSrc:e})))}function X(){var e=q(),a="".concat("/CA-NoiseGAN","/images/thumb.jpg");return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"paper",name:"Paper"}),r.a.createElement(f.a,{label:"Arxiv",variant:"outlined",color:"primary"}),r.a.createElement(b.a,{item:!0},r.a.createElement(p.a,{href:"",target:"_blank",rel:"noopener"},r.a.createElement(T,{title:"Learning Camera-Aware Noise Models, ECCV 2020 (arxiv)",elevation:0,imageSrc:a}))),r.a.createElement(V,{anchor:"citation",name:"Citation"}),r.a.createElement(h.a,{align:"left",variant:"h6",color:"inherit",gutterBottom:!0},'Ke-Chi Chang, Ren Wang, Hung-Jin Lin, Yu-Lun Liu, Chia-Ping Chen, Yu-Lin Chang, and Hwann-Tzong Chen, "Learning Camera-Aware Noise Models", in Proceedings\n  of the European Conference on Computer Vision (ECCV), 2020'),r.a.createElement(f.a,{label:"BibTeX",variant:"outlined",color:"primary"}),r.a.createElement(E.a,{elevation:0,className:e.bibtexSpan},r.a.createElement(h.a,{align:"left",variant:"h6",color:"inherit",gutterBottom:!0},r.a.createElement("pre",{style:{wordWrap:"break-word",whiteSpace:"pre-wrap"}},"@inproceedings{chang2020canoisegan,\n    author    = {Chang, Ke-Chi and Wang, Ren and Lin, Hung-Jin and Liu, Yu-Lun and Chen, Chia-Ping and Chang, Yu-Lin and Chen, Hwann-Tzong},\n    title     = {Learning Camera-Aware Noise Models},\n    booktitle = {European Conference on Computer Vision},\n    year      = {2020}\n  }"))))}function $(){var e=[{name:"Code",url:"https://github.com/arcchang1236/CA-NoiseGAN",icon:v.a},{name:"Supplementary",url:"",icon:C.a},{name:"Results",url:"",icon:N.a}];return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"video",name:"Video"}),r.a.createElement(b.a,{container:!0,justify:"center",spacing:1},r.a.createElement("iframe",{title:"ytVideo",width:"660",height:"415",src:"https://www.youtube.com/embed/_gScv9bAdTE",frameBorder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0})),r.a.createElement(V,{anchor:"download",name:"Downloadables (will release before 8/23)"}),r.a.createElement(b.a,{container:!0,justify:"center",spacing:1},e.map((function(e){return r.a.createElement(b.a,{item:!0,xs:2,key:e.url},r.a.createElement(p.a,{href:e.url,target:"_blank",rel:"noopener"},r.a.createElement(_.a,{component:e.icon,color:"action",style:{fontSize:60}}),r.a.createElement(h.a,{align:"center",variant:"h6",color:"inherit"},e.name)))}))))}function ee(){var e="".concat("/CA-NoiseGAN","/images/noise_model/0_2_6400_L_noisyg.jpg"),a="".concat("/CA-NoiseGAN","/images/noise_model/0_2_6400_L_clean.jpg"),n="".concat("/CA-NoiseGAN","/images/noise_model/0_2_6400_L_clean.jpg"),t="".concat("/CA-NoiseGAN","/images/noise_model/0_2_6400_L_noise.jpg"),i={width:"100%",padding:"40px"},o={fontSize:20},l=[{mode:"Noise Models",name:"Noise Models",url:"/demo_nm",imgPath1:n,imgPath2:t},{mode:"Denoisers",name:"Denoisers",url:"/demo_nr",imgPath1:e,imgPath2:a}];return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"results",name:"Demo"}),r.a.createElement(b.a,{container:!0,justify:"center",spacing:1},l.map((function(e){return r.a.createElement(b.a,{item:!0,xs:6,key:e.url},r.a.createElement(c.b,{style:o,to:e.url},e.mode,r.a.createElement(x.a,{style:i,src:e.imgPath1,hoverSrc:e.imgPath2})))}))))}function ae(){return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"acknowledgments",name:"Resources"}),r.a.createElement(h.a,{variant:"body1",align:"left",paragraph:!0},r.a.createElement("li",null,r.a.createElement(p.a,{href:"https://www.eecs.yorku.ca/~kamel/sidd/"},"SIDD datasets")),r.a.createElement("li",null,r.a.createElement(p.a,{href:"https://github.com/BorealisAI/noise_flow"},"Noise Flow")),r.a.createElement("li",null,r.a.createElement(p.a,{href:"https://github.com/AbdoKamel/simple-camera-pipeline"},"Simple Camera Pipeline")),r.a.createElement("li",null,r.a.createElement(p.a,{href:"https://github.com/leVirve/projectize"},"Project template"),"\u2009providing by Hung-Jin Lin")))}function ne(){return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"references",name:"References"}),r.a.createElement(h.a,{align:"left",variant:"body1",color:"inherit",gutterBottom:!0},[{number:"[1] ",link:"https://arxiv.org/abs/1908.08453",text:'"Noise Flow: Noise Modeling with Conditional Normalizing Flows"',suffix:" , Abdelrahman Abdelhamed, Marcus A. Brubaker, Michael S. Brown (ICCV 2019)"},{number:"[2] ",link:"https://openaccess.thecvf.com/content_cvpr_2018/papers/Abdelhamed_A_High-Quality_Denoising_CVPR_2018_paper.pdf",text:'"A high-quality denoising dataset for smart-phone cameras"',suffix:" , Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S (CVPR 2018)"},{number:"[3] ",link:"http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Abdelhamed_NTIRE_2019_Challenge_on_Real_Image_Denoising_Methods_and_Results_CVPRW_2019_paper.pdf",text:'"Ntire 2019 challenge on real image denoising: Methods and results"',suffix:" , Abdelhamed, Abdelrahman and Timofte, Radu and Brown, Michael S (CVPR 2019 Workshop)"},{number:"[4] ",link:"https://ieeexplore.ieee.org/iel5/83/4623174/04623175.pdf?casa_token=lqod14Up1QwAAAAA:HKaCMVvbAJWJRsr00pVzanqSAOeqZBKGeRiQFdpmQ-9qr-scr7fDrUYPWrVCs0V5wH-BfN4gpWgu",text:'"Practical Poissonian-Gaussian noise modeling and fitting for single-image raw-data"',suffix:" , Foi, Alessandro and Trimeche, Mejdi and Katkovnik, Vladimir and Egiazarian, Karen"},{number:"[5] ",link:"http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Liu_Learning_Raw_Image_Denoising_With_Bayer_Pattern_Unification_and_Bayer_CVPRW_2019_paper.pdf",text:'"Learning raw image denoising with bayer pattern unification and bayer preserving augmentation"',suffix:" , Liu, Jiaming and Wu, Chi-Hao and Wang, Yuzhi and Xu, Qin and Zhou, Yuqian and Huang, Haibin and Wang, Chuan and Cai, Shaofan and Ding, Yifan and Fan, Haoqiang and others (CVPR 2019 Workshop)"},{number:"[6] ",link:"https://ieeexplore.ieee.org/iel7/83/4358840/07839189.pdf?casa_token=0BchtjrwPDgAAAAA:58lK5T8JvhJEJaQ0jMkDfKR5zVdqxywrB-_mUHfDULdCsE5gHx-L1Nb4r2Nm4jx1UAOFvuj0jbRd",text:'"Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising"',suffix:" , Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei"}].map((function(e){return r.a.createElement(r.a.Fragment,null,e.number,r.a.createElement(p.a,{href:e.link,target:"_blank",rel:"noopener"},e.text),e.suffix," ",r.a.createElement("br",null))}))))}var te=n(24),re=n(391),ie=n(398),oe=n(395),le=n(399),ce=n(91),me=n(34),se=n(23),ue=Object(A.a)((function(e){return{main:{textAlign:"center"},selectorFromControl:Object(l.a)({margin:e.spacing(1),minWidth:120},e.breakpoints.down("sm"),{marginLeft:e.spacing(.25),marginRight:e.spacing(.25)}),cleanDenoiseSmaller:Object(l.a)({},e.breakpoints.down("xs"),{marginTop:"auto"}),magnifierZoomBox:{boxShadow:"0 0 0.2em black"},magnifierZoomCaption:{paddingTop:e.spacing(1)},selectText:{"&.Mui-focused":{color:"#FFB6C1"}},select:{"&:before":{borderBottom:"1px solid #F3B3B1"},"&:after":{borderBottom:"3px solid #FFB6C1"},"&:hover:not(.Mui-disabled):not(.Mui-focused):not(.Mui-error):before":{borderBottom:"2px solid #FFB6C1"}}}}));function de(){var e=ue(),a=Object(t.useState)(1),n=Object(te.a)(a,2),i=n[0],o=n[1],l=Object(t.useState)(2),c=Object(te.a)(l,2),m=c[0],s=c[1],u="".concat("/CA-NoiseGAN","/images/denoise"),d={0:{1:"0800_04",2:"6400_02",8:"3200_01"},1:{1:"0800_04",2:"0100_04",8:"0100_01"},2:{1:"0800_02",2:"1600_01",8:"3200_02"},3:{1:"0800_01",2:"3200_02",8:"0400_02"},4:{1:"0800_02",2:"0100_01",8:"0400_01"}},g=function(e){var a=d[m][i];return"".concat(u,"/").concat(m,"_").concat(i,"_").concat(a,"_").concat(e,".jpg")},p=r.a.useMemo((function(){return Array.from({length:5}).map((function(){return r.a.createRef()}))}),[]),f=Object(ce.a)(p[0]),E=Object(te.a)(f,1)[0];return r.a.createElement(me.MagnifierContainer,null,r.a.createElement(b.a,{container:!0,spacing:2},r.a.createElement(b.a,{item:!0,xs:8,sm:4},r.a.createElement(re.a,{className:e.selectorFromControl},r.a.createElement(ie.a,{id:"NR-scene-select-helper-label"},"SIDD Scene"),r.a.createElement(oe.a,{labelId:"NR-scene-select-helper-label",id:"NR-scene-select-helper",value:i,onChange:function(e){o(e.target.value)}},[1,2,8].map((function(e){return r.a.createElement(le.a,{key:e,value:e},"Scene #",e)})))),r.a.createElement(re.a,{className:e.selectorFromControl},r.a.createElement(ie.a,{id:"NR-camera-select-helper-label"},"Camera"),r.a.createElement(oe.a,{labelId:"NR-camera-select-helper-label",id:"NR-camera-select-helper",value:m,onChange:function(e){s(e.target.value)}},[{model:"Pixel",value:0,fullVal:"Pixel-Google-google"},{model:"iPhone",value:1,fullVal:"iPhone9,3 back camera"},{model:"Samsung",value:2,fullVal:"SM-G925I-samsung-samsung"},{model:"Nexus",value:3,fullVal:"Nexus 6-motorola-google"},{model:"LG",value:4,fullVal:"LG-H815-LGE-lge"}].map((function(e){return r.a.createElement(le.a,{key:e.value,value:e.value},e.model)})))),r.a.createElement(me.MagnifierPreview,{imageSrc:g("noisy"),mouseActivation:se.MOUSE_ACTIVATION.MOUSE_DOWN,transitionSpeed:0})),r.a.createElement(b.a,{item:!0,xs:12,sm:8},r.a.createElement(b.a,{container:!0},[{name:"Real Noisy",note:"noisy"},{name:"Gaussian [6]",note:"g"},{name:"Poisson Gauss. [4]",note:"pg"},{name:"NoiseFlow [1]",note:"nf"},{name:"Real Only",note:"real"},{name:"Ours",note:"ours"},{name:"Ours + Real",note:"realours"},{name:"Ground Truth",note:"clean"}].map((function(a,n){return r.a.createElement(b.a,{item:!0,xs:3,md:3,key:a.name,ref:p[n]},r.a.createElement(h.a,{className:e.magnifierZoomCaption,variant:"subtitle2"},a.name),r.a.createElement(me.MagnifierZoom,{className:e.magnifierZoomBox,style:{height:E-5,width:E-5,opacity:"1"},imageSrc:g(a.note),transitionSpeed:0}))}))))))}function ge(){return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"references",name:"References",fontVariant:{variant:"h5"}}),r.a.createElement(h.a,{align:"left",variant:"body1",color:"inherit",gutterBottom:!0},[{number:"[1] ",link:"https://arxiv.org/abs/1908.08453",text:'"Noise Flow: Noise Modeling with Conditional Normalizing Flows"',suffix:" , Abdelrahman Abdelhamed, Marcus A. Brubaker, Michael S. Brown (ICCV 2019)"},{number:"[2] ",link:"https://openaccess.thecvf.com/content_cvpr_2018/papers/Abdelhamed_A_High-Quality_Denoising_CVPR_2018_paper.pdf",text:'"A high-quality denoising dataset for smart-phone cameras"',suffix:" , Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S (CVPR 2018)"},{number:"[3] ",link:"http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Abdelhamed_NTIRE_2019_Challenge_on_Real_Image_Denoising_Methods_and_Results_CVPRW_2019_paper.pdf",text:'"Ntire 2019 challenge on real image denoising: Methods and results"',suffix:" , Abdelhamed, Abdelrahman and Timofte, Radu and Brown, Michael S (CVPR 2019 Workshop)"},{number:"[4] ",link:"https://ieeexplore.ieee.org/iel5/83/4623174/04623175.pdf?casa_token=lqod14Up1QwAAAAA:HKaCMVvbAJWJRsr00pVzanqSAOeqZBKGeRiQFdpmQ-9qr-scr7fDrUYPWrVCs0V5wH-BfN4gpWgu",text:'"Practical Poissonian-Gaussian noise modeling and fitting for single-image raw-data"',suffix:" , Foi, Alessandro and Trimeche, Mejdi and Katkovnik, Vladimir and Egiazarian, Karen"},{number:"[5] ",link:"http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Liu_Learning_Raw_Image_Denoising_With_Bayer_Pattern_Unification_and_Bayer_CVPRW_2019_paper.pdf",text:'"Learning raw image denoising with bayer pattern unification and bayer preserving augmentation"',suffix:" , Liu, Jiaming and Wu, Chi-Hao and Wang, Yuzhi and Xu, Qin and Zhou, Yuqian and Huang, Haibin and Wang, Chuan and Cai, Shaofan and Ding, Yifan and Fan, Haoqiang and others (CVPR 2019 Workshop)"},{number:"[6] ",link:"https://ieeexplore.ieee.org/iel7/83/4358840/07839189.pdf?casa_token=0BchtjrwPDgAAAAA:58lK5T8JvhJEJaQ0jMkDfKR5zVdqxywrB-_mUHfDULdCsE5gHx-L1Nb4r2Nm4jx1UAOFvuj0jbRd",text:'"Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising"',suffix:" , Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei"}].map((function(e){return r.a.createElement(r.a.Fragment,null,e.number,r.a.createElement(p.a,{href:e.link,target:"_blank",rel:"noopener"},e.text),e.suffix," ",r.a.createElement("br",null))}))))}var he=function(){var e=ue();return r.a.createElement("div",{className:e.main},r.a.createElement(L,{title:"Learning Camera-Aware Noise Models",githubPage:"https://github.com/arcchang1236/CA-NoiseGAN",sections:[{title:"Home",url:"/"},{title:"Noise Models",url:"/demo_nm"},{title:"Denoisers",url:"/demo_nr"},{title:"References",url:"/demo_nr#references"}]}),r.a.createElement(g.a,{maxWidth:"lg"},r.a.createElement(V,{anchor:"result_denoise",name:"Denoisers"}),r.a.createElement(h.a,{paragraph:!0,align:"left"},"We compare the performance of denoisers trained from different noise models and real data. Ours + Real use the real data used in training our noise models to improve the performance. For each scene with each camera, we choose one result for visualization.",r.a.createElement("br",null),"There are more results in\u2009",r.a.createElement("a",{href:"/CA-NoiseGAN#download"},"Downloadables"),".",r.a.createElement("br",null),r.a.createElement("strong",null,"You can click the reference image anywhere to get the corresponding results. More, you can hover after click to see the dynamic change.")),r.a.createElement(de,null),r.a.createElement(ge,null)),r.a.createElement(Z,{authorName:"Ke-Chi Chang",githubPage:"https://github.com/arcchang1236"}))},pe=n(392),fe=Object(A.a)((function(e){return{main:{textAlign:"center"},selectorFromControl:Object(l.a)({margin:e.spacing(1),minWidth:120},e.breakpoints.down("sm"),{marginLeft:e.spacing(.25),marginRight:e.spacing(.25)}),cleanDenoiseSmaller:Object(l.a)({},e.breakpoints.down("xs"),{marginTop:"auto"}),magnifierZoomBox:{boxShadow:"0 0 0.2em black"},magnifierZoomCaption:{paddingTop:e.spacing(1)},selectText:{"&.Mui-focused":{color:"#FFB6C1"}},select:{"&:before":{borderBottom:"1px solid #F3B3B1"},"&:after":{borderBottom:"3px solid #FFB6C1"},"&:hover:not(.Mui-disabled):not(.Mui-focused):not(.Mui-error):before":{borderBottom:"2px solid #FFB6C1"}}}}));function be(){var e=fe(),a=Object(t.useState)(1),n=Object(te.a)(a,2),i=n[0],o=n[1],l=Object(t.useState)(2),c=Object(te.a)(l,2),m=c[0],s=c[1],u=Object(t.useState)("0100_H"),d=Object(te.a)(u,2),g=d[0],p=d[1],f="".concat("/CA-NoiseGAN","/images/noise_model"),E=[{name:"Gaussian [6]",note:"g"},{name:"Poisson Gauss. [4]",note:"pg"},{name:"NoiseFlow [1]",note:"nf"},{name:"Ours",note:"ours"},{name:"Ground Truth",note:"noise"}],_={0:{1:["0100_N","0800_L","0800_N"],2:["0100_H","0800_L","0800_N","6400_L"],8:["0100_N","0800_N","3200_L"]},1:{1:["0800_L","1600_L"],2:["0800_L","1600_L"],8:["0100_H","0100_N","0800_N","3200_L"]},2:{1:["0100_H","0100_N","0800_N","3200_L"],2:["1600_N"],8:["0800_N","1600_N","3200_N"]},3:{1:["0800_N"],2:["3200_L"],8:["0800_L","1600_L"]},4:{1:["0800_L"],2:["0800_L"],8:["0100_N","0400_N"]}},v=function(e){var a="noisynoise"===e?"noisy":"".concat(e);return"".concat(f,"/").concat(m,"_").concat(i,"_").concat(g,"_").concat(a,".jpg")},C=r.a.useMemo((function(){return Array.from({length:5}).map((function(){return r.a.createRef()}))}),[]),N=Object(ce.a)(C[0]),A=Object(te.a)(N,1)[0];return r.a.createElement(me.MagnifierContainer,null,r.a.createElement(b.a,{container:!0,spacing:2,justify:"center"},r.a.createElement(b.a,{item:!0,xs:4,sm:4},r.a.createElement(pe.a,{row:!0},r.a.createElement(re.a,{className:e.selectorFromControl},r.a.createElement(ie.a,{id:"NM-camera-select-helper-label"},"Camera"),r.a.createElement(oe.a,{labelId:"NM-camera-select-helper-label",id:"NM-camera-select-helper",value:m,onChange:function(e){s(e.target.value);var a=_[e.target.value][i][0];p(a)}},[{model:"Pixel",value:0,fullVal:"Pixel-Google-google"},{model:"iPhone",value:1,fullVal:"iPhone9,3 back camera"},{model:"Samsung",value:2,fullVal:"SM-G925I-samsung-samsung"},{model:"Nexus",value:3,fullVal:"Nexus 6-motorola-google"},{model:"LG",value:4,fullVal:"LG-H815-LGE-lge"}].map((function(e){return r.a.createElement(le.a,{key:e.value,value:e.value},e.model)})))),r.a.createElement(re.a,{className:e.selectorFromControl},r.a.createElement(ie.a,{id:"NM-scene-select-helper-label"},"SIDD Scene"),r.a.createElement(oe.a,{labelId:"NM-scene-select-helper-label",id:"NM-scene-select-helper",value:i,onChange:function(e){o(e.target.value);var a=_[m][e.target.value][0];p(a)}},[1,2,8].map((function(e){return r.a.createElement(le.a,{key:e,value:e},"Scene #",e)})))),r.a.createElement(re.a,{className:e.selectorFromControl},r.a.createElement(ie.a,{id:"NM-idx-select-helper-label"},"Conditions"),r.a.createElement(oe.a,{labelId:"NM-idx-select-helper-label",id:"NM-idx-select-helper",value:g,onChange:function(e){p(e.target.value)}},_[m][i].map((function(e){return r.a.createElement(le.a,{key:e,value:e},e)})))))),r.a.createElement(b.a,{item:!0,xs:5,sm:5},r.a.createElement(me.MagnifierPreview,{imageSrc:v("noisy"),mouseActivation:se.MOUSE_ACTIVATION.MOUSE_DOWN,transitionSpeed:0}))),r.a.createElement(b.a,{container:!0,justify:"center"},E.map((function(a){return r.a.createElement(b.a,{item:!0,xs:2,md:2,key:a.name},r.a.createElement(h.a,{className:e.magnifierZoomCaption,variant:"subtitle2"},a.name),r.a.createElement(me.MagnifierZoom,{className:e.magnifierZoomBox,style:{height:A-5,width:A-5,opacity:"1"},transitionSpeed:0,imageSrc:v(a.note)}))}))),r.a.createElement(b.a,{container:!0,justify:"center"},E.map((function(a,n){return r.a.createElement(b.a,{item:!0,xs:2,md:2,key:a.name,ref:C[n]},r.a.createElement(h.a,{className:e.magnifierZoomCaption,variant:"subtitle2"},a.name),r.a.createElement(me.MagnifierZoom,{className:e.magnifierZoomBox,style:{height:A-5,width:A-5,opacity:"1"},transitionSpeed:0,imageSrc:v("noisy".concat(a.note))}))}))))}function Ee(){return r.a.createElement(r.a.Fragment,null,r.a.createElement(V,{anchor:"references",name:"References",fontVariant:{variant:"h5"}}),r.a.createElement(h.a,{align:"left",variant:"body1",color:"inherit",gutterBottom:!0},[{number:"[1] ",link:"https://arxiv.org/abs/1908.08453",text:'"Noise Flow: Noise Modeling with Conditional Normalizing Flows"',suffix:" , Abdelrahman Abdelhamed, Marcus A. Brubaker, Michael S. Brown (ICCV 2019)"},{number:"[2] ",link:"https://openaccess.thecvf.com/content_cvpr_2018/papers/Abdelhamed_A_High-Quality_Denoising_CVPR_2018_paper.pdf",text:'"A high-quality denoising dataset for smart-phone cameras"',suffix:" , Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S (CVPR 2018)"},{number:"[3] ",link:"http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Abdelhamed_NTIRE_2019_Challenge_on_Real_Image_Denoising_Methods_and_Results_CVPRW_2019_paper.pdf",text:'"Ntire 2019 challenge on real image denoising: Methods and results"',suffix:" , Abdelhamed, Abdelrahman and Timofte, Radu and Brown, Michael S (CVPR 2019 Workshop)"},{number:"[4] ",link:"https://ieeexplore.ieee.org/iel5/83/4623174/04623175.pdf?casa_token=lqod14Up1QwAAAAA:HKaCMVvbAJWJRsr00pVzanqSAOeqZBKGeRiQFdpmQ-9qr-scr7fDrUYPWrVCs0V5wH-BfN4gpWgu",text:'"Practical Poissonian-Gaussian noise modeling and fitting for single-image raw-data"',suffix:" , Foi, Alessandro and Trimeche, Mejdi and Katkovnik, Vladimir and Egiazarian, Karen"},{number:"[5] ",link:"http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Liu_Learning_Raw_Image_Denoising_With_Bayer_Pattern_Unification_and_Bayer_CVPRW_2019_paper.pdf",text:'"Learning raw image denoising with bayer pattern unification and bayer preserving augmentation"',suffix:" , Liu, Jiaming and Wu, Chi-Hao and Wang, Yuzhi and Xu, Qin and Zhou, Yuqian and Huang, Haibin and Wang, Chuan and Cai, Shaofan and Ding, Yifan and Fan, Haoqiang and others (CVPR 2019 Workshop)"},{number:"[6] ",link:"https://ieeexplore.ieee.org/iel7/83/4358840/07839189.pdf?casa_token=0BchtjrwPDgAAAAA:58lK5T8JvhJEJaQ0jMkDfKR5zVdqxywrB-_mUHfDULdCsE5gHx-L1Nb4r2Nm4jx1UAOFvuj0jbRd",text:'"Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising"',suffix:" , Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei"}].map((function(e){return r.a.createElement(r.a.Fragment,null,e.number,r.a.createElement(p.a,{href:e.link,target:"_blank",rel:"noopener"},e.text),e.suffix," ",r.a.createElement("br",null))}))))}var _e=function(){var e=fe();return r.a.createElement("div",{className:e.main},r.a.createElement(L,{title:"Learning Camera-Aware Noise Models",githubPage:"https://github.com/arcchang1236/CA-NoiseGAN",sections:[{title:"Home",url:"/"},{title:"Noise Models",url:"/demo_nm"},{title:"Denoisers",url:"/demo_nr"},{title:"References",url:"/demo_nm#references"}]}),r.a.createElement(g.a,{maxWidth:"lg"},r.a.createElement(V,{anchor:"result_noise",name:"Noise Models"}),r.a.createElement(h.a,{paragraph:!0,align:"left"},"The synthetic noise samples of several noise modeling methods on different clean images with different ISO/lighting conditions are visualized. Ours have many clear structures that fit the texture of clean images and real noise. Note that the noise value is scaled up for better visualization purpose.",r.a.createElement("br",null),"Conditions include ISO level and lighting condition (H: High, N: Normal, L: Low).",r.a.createElement("br",null),"There are more results in\u2009",r.a.createElement("a",{href:"/CA-NoiseGAN#download"},"Downloadables"),".",r.a.createElement("br",null),r.a.createElement("strong",null,"You can click the reference image anywhere to get the corresponding results. More, you can hover after click to see the dynamic change.")),r.a.createElement(be,null),r.a.createElement(Ee,null)),r.a.createElement(Z,{authorName:"Ke-Chi Chang",githubPage:"https://github.com/arcchang1236"}))},ve=Object(s.a)({typography:{fontFamily:["Source Sans Pro","-apple-system","BlinkMacSystemFont",'"Segoe UI"',"Roboto",'"Helvetica Neue"',"Arial","sans-serif",'"Apple Color Emoji"','"Segoe UI Emoji"','"Segoe UI Symbol"'].join(",")},palette:{primary:{main:"#666"},secondary:{main:"#7777ce"}}});ve.typography.h3=Object(l.a)({fontSize:"1.65rem",lineHeight:"1.167",fontWeight:400,fontFamily:ve.typography.fontFamily},ve.breakpoints.up("md"),{fontSize:"3rem"}),ve.typography.h6=Object(l.a)({fontSize:"1.0rem",lineHeight:"1.6",fontWeight:500,fontFamily:ve.typography.fontFamily},ve.breakpoints.up("md"),{fontSize:"1.25rem"});var Ce=function(){return r.a.createElement(u.a,{theme:ve},r.a.createElement("div",null,r.a.createElement(d.a,null),r.a.createElement(c.a,{basename:"/CA-NoiseGAN"},r.a.createElement("div",null,r.a.createElement(m.a,{path:"/",exact:!0,component:J}),r.a.createElement(m.a,{path:"/demo_nr",component:he}),r.a.createElement(m.a,{path:"/demo_nm",component:_e})))))};Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));o.a.render(r.a.createElement(Ce,null),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}},[[191,1,2]]]);
//# sourceMappingURL=main.4054bb2c.chunk.js.map